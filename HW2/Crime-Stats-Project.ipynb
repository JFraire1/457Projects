{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "55e6b918-afac-43e8-b338-43f8ac64014f",
      "metadata": {
        "id": "55e6b918-afac-43e8-b338-43f8ac64014f"
      },
      "source": [
        "##  Deep Neural Networks Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a8e066d-2849-4a6e-9c71-bb98d605ae07",
      "metadata": {
        "id": "1a8e066d-2849-4a6e-9c71-bb98d605ae07"
      },
      "source": [
        "In this project, you will be working with a real-world data set from the Las Vegas Metropolitan Police Department. The dataset  contains information about the reported incidents, including the time and location of the crime, type of incident, and number of persons involved."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e87fac7-352a-4c39-b087-76254b5e2743",
      "metadata": {
        "id": "9e87fac7-352a-4c39-b087-76254b5e2743"
      },
      "source": [
        "The dataset is downloaded from the public docket at:\n",
        "https://opendata-lvmpd.hub.arcgis.com\n",
        "\n",
        "let's read the csv file and transform the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "637211a4-582f-426b-a127-c3f284463f35",
      "metadata": {
        "id": "637211a4-582f-426b-a127-c3f284463f35"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "bcf40b02-80b6-4abc-a662-f7ed50a65181",
      "metadata": {
        "id": "bcf40b02-80b6-4abc-a662-f7ed50a65181"
      },
      "outputs": [],
      "source": [
        "orig_df = pd.read_csv('../../datasets/LVMPD-Stats.csv', parse_dates=['ReportedOn'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "e1ca1d15-3955-4971-a3c4-c1a73b62edda",
      "metadata": {
        "id": "e1ca1d15-3955-4971-a3c4-c1a73b62edda"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('datasets/LVMPD-Stats.csv', parse_dates=['ReportedOn'],\n",
        "                 usecols = ['X', 'Y', 'ReportedOn',\n",
        "                            'Area_Command','NIBRSOffenseCode',\n",
        "                            'VictimCount' ] )\n",
        "\n",
        "df['DayOfWeek'] = df['ReportedOn'].dt.day_name()\n",
        "df['Time' ]     = df['ReportedOn'].dt.hour\n",
        "df.drop(columns = 'ReportedOn', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "3ddc413d-ba3f-4204-bc18-7fdd4de8d221",
      "metadata": {
        "id": "3ddc413d-ba3f-4204-bc18-7fdd4de8d221"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['X'] = df['X']\n",
        "df['Y'] = df['Y']\n",
        "df['Time'] = pd.factorize(df['Time'])[0]\n",
        "df['DayOfWeek'] = pd.factorize(df['DayOfWeek'])[0]\n",
        "df.Area_Command = pd.factorize(df['Area_Command'])[0]\n",
        "df.VictimCount = pd.factorize(df['VictimCount'])[0]\n",
        "df.NIBRSOffenseCode = pd.factorize(df['NIBRSOffenseCode'])[0]\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "a9c6162f-9686-4195-818d-950a6368c686",
      "metadata": {
        "id": "a9c6162f-9686-4195-818d-950a6368c686"
      },
      "outputs": [],
      "source": [
        "df= df[['X', 'Y', 'Area_Command', 'NIBRSOffenseCode',\n",
        "       'DayOfWeek', 'Time','VictimCount']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a90bc78a-6d1b-4fe4-a1b0-8333aec1c851",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a90bc78a-6d1b-4fe4-a1b0-8333aec1c851",
        "outputId": "18117774-1692-44c5-d5f6-d627e1346c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "df.values.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651605b1-8d2c-4d3e-a09e-9aef6e550fc6",
      "metadata": {
        "id": "651605b1-8d2c-4d3e-a09e-9aef6e550fc6"
      },
      "source": [
        "# Goal\n",
        "The goal is to build a predictive model that is trained on the following data:\n",
        "* latitude and longitude (location)\n",
        "* Hour of the day\n",
        "* Day of the week\n",
        "* Area-of-command code: The police designation of the bureau of the operation.\n",
        "* Classification code for the crime committed\n",
        "  \n",
        "The predicted variable is the number of persons involved in the accident.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e54f0b8-83f9-4db9-88f9-f5a595342069",
      "metadata": {
        "id": "0e54f0b8-83f9-4db9-88f9-f5a595342069"
      },
      "source": [
        "## Task 1\n",
        "* print a few rows of the values in the dataframe ``df`` and explain what each column of data means.\n",
        "* identify the input and target variables\n",
        "* what is the range of values in each column? Do you need to scale, shift or normalize your data?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "X is longitude, Y is latitude\n",
        "  Will normalize\n",
        "\n",
        "Area_command is the police designation of the bureau of the operation, encoded as an integer\n",
        "  Categorical data, can be one-hot encoded but is not really needed\n",
        "\n",
        "NIBRSOffenseCode is the code for the crime commited, encoded as an integer with range of 2\n",
        "  Categorical data, same as above, already encoded using numbers\n",
        "\n",
        "DayofWeek is self-explanatory encoded as integer value with range of 7\n",
        "  Categorical data, same as above, range of values is low\n",
        "\n",
        "Time is the hour of day encoded as an integer\n",
        "\n",
        "\n",
        "VictimCounts is the target\n",
        "'''\n",
        "df['X'] = (df['X']-df['X'].mean())/df['X'].std()\n",
        "df['Y'] = (df['Y']-df['Y'].mean())/df['Y'].std()\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqqkJD4ixf6S",
        "outputId": "7471b3ac-dbea-4be1-977f-50b9bf2ba7b4"
      },
      "id": "tqqkJD4ixf6S",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          X         Y  Area_Command  NIBRSOffenseCode  DayOfWeek  Time  \\\n",
            "0  0.708907  0.619351             0                 0          0     0   \n",
            "1 -0.798132  0.391269             1                 1          1     1   \n",
            "2  0.160300  0.320637             2                 1          2     0   \n",
            "3 -0.648490 -0.217249             3                 1          1     2   \n",
            "4 -0.171602 -0.400214             4                 1          1     3   \n",
            "\n",
            "   VictimCount  \n",
            "0            0  \n",
            "1            0  \n",
            "2            1  \n",
            "3            2  \n",
            "4            0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5549ecc9-3c0b-4efa-9a1f-340a25a1e4be",
      "metadata": {
        "id": "5549ecc9-3c0b-4efa-9a1f-340a25a1e4be"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "* Create two `DataLoader` objects for training and testing based on the input and output variables. Pick a reasonable batch size and verify the shape of data by iterating over the one dataset and printing the shape of the batched data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "00fe4287-934b-4799-9e43-c3571acfbab4",
      "metadata": {
        "id": "00fe4287-934b-4799-9e43-c3571acfbab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8addc528-afa8-4590-a39a-f284702ac2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([3, 6]) torch.Size([3, 1])\n",
            "\n",
            "\n",
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([40, 6]) torch.Size([40, 1])\n",
            "torch.Size([32, 6]) torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 40\n",
        "n_iters = 3000\n",
        "train_dataframe, test_dataframe = train_test_split(df, test_size=0.3)\n",
        "\n",
        "\n",
        "train_y = train_dataframe[['VictimCount']]\n",
        "train_x = train_dataframe\n",
        "train_x.drop(['VictimCount'], axis=1, inplace=True)\n",
        "\n",
        "tensor_train_y = torch.Tensor(train_y.to_numpy())\n",
        "tensor_train_x = torch.Tensor(train_x.to_numpy())\n",
        "train_dataset = TensorDataset(tensor_train_x, tensor_train_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "\n",
        "test_y = test_dataframe[['VictimCount']]\n",
        "test_x = test_dataframe\n",
        "test_x.drop(['VictimCount'], axis=1, inplace=True)\n",
        "\n",
        "tensor_test_y = torch.Tensor(test_y.to_numpy())\n",
        "tensor_test_x = torch.Tensor(test_x.to_numpy())\n",
        "test_dataset = TensorDataset(tensor_test_x, tensor_test_y)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "for batch in test_loader:\n",
        "  x, y = batch\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for batch in train_loader:\n",
        "  x, y = batch\n",
        "  print(x.shape, y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb6f08c-5e70-4b14-b62c-4686d9f7aace",
      "metadata": {
        "id": "1fb6f08c-5e70-4b14-b62c-4686d9f7aace"
      },
      "source": [
        "## Task 3\n",
        "In this task you will try to predict number of crime victims as a **real number**. Therefore the machine learning problem is a **regression** problem.\n",
        "\n",
        "* Define the proper loss function for this task\n",
        "* what should the size of the predicted output be?\n",
        "* explain your choice of architecture, including how many layers you will be using\n",
        "* define an optimizer for training this model, choose a proper learning rate\n",
        "* write a training loop that obtains a batch out of the  training data and calculates the forward and backward passes over the neural network. Call the optimizer to update the weights of the neural network.\n",
        "* write a for loop that continues the training over a number of epochs. At the end of each epoch, calculate the ``MSE`` error on the test data and print it.\n",
        "* is your model training well? Adjust the learning rate, hidden size of the network, and try different activation functions and number of layers to achieve the best accuracy and report it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.MSELoss()\n",
        "# MSE loss as it is regression, we compare output to expected result\n",
        "# The output should be a single scalar prediction of the count of victims\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ALjU3IEHmZuN"
      },
      "id": "ALjU3IEHmZuN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86e3fc70-c6ce-4589-9930-128951290e8d",
      "metadata": {
        "id": "86e3fc70-c6ce-4589-9930-128951290e8d"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "In this task, you will try to predict the number of crime victims as a **class number**. Therefore the machine learning problem is a **classification** problem.\n",
        "\n",
        "* Repeat all the steps in task 3. Specifically, pay attention to the differences with regression.\n",
        "* How would you find the number of classes on the output data?\n",
        "* How is the architecture different?\n",
        "* How is the loss function different?\n",
        "* Calculate the Accuracy for test data as the number of correct classified outputs divided by the total number of test data in each epoch. Report it at the end of each epoch\n",
        "* Try a few variations of learning rate, hidden dimensions, layers, etc. What is the best accuracy that you can get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d929c52-af34-4081-92cd-3463a3fc4db1",
      "metadata": {
        "id": "7d929c52-af34-4081-92cd-3463a3fc4db1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "84d2a304-6197-4cd9-b31e-745f7862f213",
      "metadata": {
        "id": "84d2a304-6197-4cd9-b31e-745f7862f213"
      },
      "source": [
        "## Task 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e4ef16-d828-45e5-bd58-1c49fcfecf52",
      "metadata": {
        "id": "d6e4ef16-d828-45e5-bd58-1c49fcfecf52"
      },
      "source": [
        "### Reflect on your results\n",
        "\n",
        "* Write a paragraph about your experience with tasks 3 and 4. How do you compare the results? Which one worked better? Why?\n",
        "* Write a piece of code that finds an example of a  miss-classification. Calculate the probabilities for the output classes and plot them in a bar chart. Also, indicate what is the correct class label."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b000b0b-fa37-4f8d-8ec7-0a1e6e749424",
      "metadata": {
        "id": "5b000b0b-fa37-4f8d-8ec7-0a1e6e749424"
      },
      "source": [
        "## Task 6: Exploring the patterns in raw data\n",
        "\n",
        "* Plot the crime incidents as a `scatter` plot using the corrdinates. Use the color property of each datapoint to indicate the day of the week. Is there a pattern in the plot?\n",
        "* Now make a new scatter plot and use the color property of each datapoint to indicate the number of persons involved in the incident. Is there a pattern here?\n",
        "* use numpy (or pandas if you like) to sort the number of crimes reported by the day of the week. What days are most frequent?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b396aaf-5d1a-49cd-ae1d-b63af7e561f5",
      "metadata": {
        "id": "5b396aaf-5d1a-49cd-ae1d-b63af7e561f5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}